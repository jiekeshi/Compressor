We prepare the finetuned model here:
You can download it via:
```
wget https://smu-my.sharepoint.com/:u:/g/personal/jiekeshi_smu_edu_sg/EXDu1rWTz3NGiSlCkgeyFUIBB1lBwa1qmsFRTet4OxLljg?download=1 -O ../checkpoint/model.bin
```
## Evaluation
For evaluating the fine-tuned model, please run:
```
mkdir -p ../logs
CUDA_VISIBLE_DEVICES=1 python3 main.py \
    --output_dir=../checkpoint \
    --model_type=roberta \
    --config_name=microsoft/graphcodebert-base \
    --tokenizer_name=microsoft/graphcodebert-base \
    --model_name_or_path=microsoft/graphcodebert-base \
    --do_eval \
    --train_data_file=../../../data/vulnerability_prediction/label_train.jsonl \
    --eval_data_file=../../../data/vulnerability_prediction/test.jsonl \
    --test_data_file=../../../data/vulnerability_prediction/test.jsonl \
    --epoch 10 \
    --code_length 384 \
    --data_flow_length 128 \
    --train_batch_size 16 \
    --eval_batch_size 64 \
    --learning_rate 2e-5 \
    --max_grad_norm 1.0 \
    --evaluate_during_training \
    --seed 123456 2>&1 | tee ../logs/eval.log
```

# Getting soft labels
For getting soft labels to do knowledge distillation later, please run:
```
mkdir -p ../logs
CUDA_VISIBLE_DEVICES=1 python3 main.py \
    --output_dir=../checkpoint \
    --model_type=roberta \
    --config_name=microsoft/graphcodebert-base \
    --tokenizer_name=microsoft/graphcodebert-base \
    --model_name_or_path=microsoft/graphcodebert-base \
    --do_eval \
    --train_data_file=../../../data/vulnerability_prediction/label_train.jsonl \
    --eval_data_file=../../../data/vulnerability_prediction/test.jsonl \
    --test_data_file=../../../data/vulnerability_prediction/unlabel_train.jsonl \
    --epoch 10 \
    --code_length 384 \
    --data_flow_length 128 \
    --train_batch_size 16 \
    --eval_batch_size 64 \
    --learning_rate 2e-5 \
    --max_grad_norm 1.0 \
    --evaluate_during_training \
    --seed 123456
```
You will see the `preds_unlabel_train_gcb.npy` in `../../../data/vulnerability_prediction/`. 

You will also see that the log outputs say the accuracy is 0. Don't worry,  `unlabel_train.jsonl` has no true labels, so the accuracy is not true.


## Finetuning
If you'd like to finetune a model from scratch, please run:
```
python3 main.py \
    --output_dir=../checkpoint \
    --model_type=roberta \
    --config_name=microsoft/graphcodebert-base \
    --tokenizer_name=microsoft/graphcodebert-base \
    --model_name_or_path=microsoft/graphcodebert-base \
    --do_train \
    --train_data_file=../../../data/defect_detection/label_train.jsonl \
    --eval_data_file=../../../data/defect_detection/valid.jsonl \
    --test_data_file=../../../data/defect_detection/test.jsonl \
    --epoch 10 \
    --code_length 384 \
    --data_flow_length 128 \
    --train_batch_size 16 \
    --eval_batch_size 64 \
    --learning_rate 2e-5 \
    --max_grad_norm 1.0 \
    --evaluate_during_training \
    --seed 123456  2>&1 | tee ../logs/train.log
```
